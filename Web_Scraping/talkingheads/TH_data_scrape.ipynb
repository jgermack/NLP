{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web page scraping\n",
    "The code below scrapes a number of web pages to get the song titles and lyrics from songs  \n",
    "by the Talking Heads. The task is accomplished in two parts. First an index page is scraped  \n",
    "to get the song pages and those urls are used to get the actual song titles and song lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape index page\n",
    "We start by openning the page with links to all Talking Heads songs in the site.  \n",
    "After parsing that page, all \"href\" links are captured in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_links = urlopen(\"http://www.allthelyrics.com/lyrics/talking_heads\")\n",
    "bsobj_links = bs(data_links.read(), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the links -- href data to list \n",
    "page_links = []\n",
    "for link in bsobj_links.find_all('a'):\n",
    "    page_links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting page names\n",
    "The list of page links is then converted to a comma seperated string.  \n",
    "The links for only song pages are extracted by using a regular expression.  \n",
    "Being that results from appling a regular expression are returned as a list,  \n",
    "another string is created from this list and a regular expression extracts the  \n",
    "page name with the \"html\" file type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create strings and extract the specific text from all href data\n",
    "string = ' , '.join(page_links)\n",
    "page_list = re.findall('lyrics/talking_heads/.*html', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create strings and extract the song page name from href data\n",
    "# to be used for individual page scraping\n",
    "page_strings = ','.join(page_list)\n",
    "page = re.findall('[A-Za-z0-9_-]*\\.html', page_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Scraping song title and lyrics\n",
    "Now that we have a list of page names, I created 2 empty lists that  \n",
    "will hold the song titles and song lyrics as they are scraped from  \n",
    "the pages. I created a function that will open a page, scrape the text  \n",
    "and append the results to the appropriate list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_title = []\n",
    "song_lyric = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to scrape the pages\n",
    "def getWords(page):\n",
    "    data = urlopen('http://www.allthelyrics.com/lyrics/talking_heads/' + page)\n",
    "    bsobj = bs(data.read(), 'html.parser')\n",
    "\n",
    "    for item in bsobj.findAll(class_= 'page-title'):\n",
    "        song_title.append(item.get_text())\n",
    "        \n",
    "    for item in bsobj.findAll(class_= 'content-text-inner'):\n",
    "        song_lyric.append(item.get_text())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scraping song title and lyrics part 2\n",
    "The scraping function iterates over each page capturing the desired text.  \n",
    "Each list is converted to a string with a pipe \"|\" used for a delimiter as that  \n",
    "character would be unlikely to show up in the titles or lyrics. Finally, those strings  \n",
    "are written to text files for storage in a database and used in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop through all pages and apply the scraping function\n",
    "for i in page:\n",
    "    getWords(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create strings from the list and join with pipe\n",
    "song_title = '|' .join(song_title)\n",
    "song_lyric = '|' .join(song_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write title and lyric strings to text files\n",
    "title_data = codecs.open('/media/jim/Samsung USB/Talking_Heads/TH_titles.txt', mode=\"w\", encoding=\"UTF-8\")\n",
    "title_data.write(song_title)\n",
    "title_data.close()\n",
    "\n",
    "lyric_data = codecs.open('/media/jim/Samsung USB/Talking_Heads/TH_lyrics.txt', mode=\"w\", encoding=\"UTF-8\")\n",
    "lyric_data.write(song_lyric)\n",
    "lyric_data.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
